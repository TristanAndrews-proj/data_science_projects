{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Hacker News\n",
    "- In this project, we will be exploring posts on Hacker News, one of the most poppular News website in the world where users submits posts that are voted and commented on (similar to reddit).\n",
    "- Hacker News is popular in Technology and start-up circles, and the posts that make it to the top of Hacker News gets hundreds of thousands of views as a result\n",
    "- What we will be doing in this project is quite simple: we will be working with a dataset which originally had 300,000 rows of data but was then reduced down to 20,000. We only wanted to focus on posts that had comments/ feedback.\n",
    "- We're specifically interested in posts whose titles begin with `AskHN` or show `ShowHN`\n",
    "- From there we will be making comparisons on these posts by analyzing the following: \n",
    "    - Do Ask HN or Show HN receive more comments on average?\n",
    "    - Do posts created at a certain time receive more comments on average?\n",
    "    \n",
    "STEP ONE:\n",
    "- We will start off by importing the libraries we need and reading the datasets into a list of lists below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52']\n",
      "['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30']\n",
      "['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20']\n",
      "['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']\n"
     ]
    }
   ],
   "source": [
    "from csv import reader\n",
    "opened_file = open('hacker_news.csv')\n",
    "read_file = reader(opened_file)\n",
    "hn = list(read_file)\n",
    "\n",
    "# Printing out the first 5 rows of the dataset including the header\n",
    "for row in hn[0:5]:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP TWO:\n",
    "- Extract all headers from the dataset and save them in a seperate variable.\n",
    "- Update dataset without headers. Print first 5 rows of updated dataset to check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52']\n",
      "['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30']\n",
      "['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20']\n",
      "['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']\n",
      "['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']\n"
     ]
    }
   ],
   "source": [
    "headers = hn[0] #Extracted headers from the dataset and saved them to variable headers\n",
    "hn = hn[1:] #Dataset without the headers\n",
    "for row in hn[0:5]: #Displaying first 5 rows of updated dataset without the headers\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP THREE:\n",
    "- Seperate ask posts and show posts rows from other posts in their own seperate lists. Display first five rows of Ask posts and Show posts to check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Ask Posts: 1744\n",
      "# Show Posts: 1162\n",
      "# Other Posts: 17194\n"
     ]
    }
   ],
   "source": [
    "#Create 3 empty lists: 1 for ask posts, 1 for show posts, and 1 for other posts\n",
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for row in hn:\n",
    "    title = row[1]\n",
    "    title_lc = title.lower()\n",
    "    if title_lc.startswith('ask hn'): #Adding rows from dataset w/titles starting with 'ask hn' to 'ask_posts' list\n",
    "        ask_posts.append(row)\n",
    "    elif title_lc.startswith('show hn'): #Adding rows from dataset w/titles starting with 'show hn' to 'show_posts' list\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)#Adding rows from dataset w/titles that have other titles to 'other_posts' list\n",
    "\n",
    "print('# Ask Posts:',len(ask_posts))\n",
    "print('# Show Posts:', len(show_posts))\n",
    "print('# Other Posts:', len(other_posts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 Ask posts rows: \n",
      "['12296411', 'Ask HN: How to improve my personal website?', '', '2', '6', 'ahmedbaracat', '8/16/2016 9:55']\n",
      "['10610020', 'Ask HN: Am I the only one outraged by Twitter shutting down share counts?', '', '28', '29', 'tkfx', '11/22/2015 13:43']\n",
      "['11610310', 'Ask HN: Aby recent changes to CSS that broke mobile?', '', '1', '1', 'polskibus', '5/2/2016 10:14']\n",
      "['12210105', 'Ask HN: Looking for Employee #3 How do I do it?', '', '1', '3', 'sph130', '8/2/2016 14:20']\n",
      "['10394168', 'Ask HN: Someone offered to buy my browser extension from me. What now?', '', '28', '17', 'roykolak', '10/15/2015 16:38']\n",
      "First 5 Show posts rows:\n",
      "['10627194', 'Show HN: Wio Link  ESP8266 Based Web of Things Hardware Development Platform', 'https://iot.seeed.cc', '26', '22', 'kfihihc', '11/25/2015 14:03']\n",
      "['10646440', 'Show HN: Something pointless I made', 'http://dn.ht/picklecat/', '747', '102', 'dhotson', '11/29/2015 22:46']\n",
      "['11590768', 'Show HN: Shanhu.io, a programming playground powered by e8vm', 'https://shanhu.io', '1', '1', 'h8liu', '4/28/2016 18:05']\n",
      "['12178806', 'Show HN: Webscope  Easy way for web developers to communicate with Clients', 'http://webscopeapp.com', '3', '3', 'fastbrick', '7/28/2016 7:11']\n",
      "['10872799', 'Show HN: GeoScreenshot  Easily test Geo-IP based web pages', 'https://www.geoscreenshot.com/', '1', '9', 'kpsychwave', '1/9/2016 20:45']\n"
     ]
    }
   ],
   "source": [
    "#Displaying first 5 rows the lists we are focusing on in this project\n",
    "print('First 5 Ask posts rows: ')\n",
    "for row in ask_posts[0:5]:\n",
    "    print(row)\n",
    "\n",
    "print('First 5 Show posts rows:')\n",
    "for row in show_posts[0:5]:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ask comments: 8.424982794218858\n",
      "Average show comments:  4.125258086717137\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments = 0\n",
    "total_comments = len(ask_posts) + len(show_posts)\n",
    "for row in ask_posts:\n",
    "    num_comments = int(row[4])\n",
    "    total_ask_comments += num_comments\n",
    "\n",
    "avg_ask_comments = total_ask_comments / total_comments\n",
    "print('Average ask comments:',avg_ask_comments)\n",
    "\n",
    "total_show_comments = 0\n",
    "for row in show_posts:\n",
    "    num_comments = int(row[4])\n",
    "    total_show_comments += num_comments\n",
    "\n",
    "avg_show_comments = total_show_comments / total_comments\n",
    "print('Average show comments: ',avg_show_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANALYSIS\n",
    "- As you can see, ask posts receive more comments on average than show posts\n",
    "- The reason for this is because people generally respond to when a person is asking something on a post more than a person showing something. People in ask posts expect or need feedback on their ask posts because they need help with something."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP FOUR: \n",
    "- Since we have determined that Ask posts receive more comments than show posts on average, we'll be focusing on just these posts.\n",
    "- Next, we'll determine if ask posts created at a certain time are more likely to attract comments. We'll use the following steps to perform this analysis:\n",
    "    - Calculate the amount of ask posts created in each hour of the day, along with the number of comments received.\n",
    "    - Calculate the average number of comments ask posts receive by hour created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "result_list = []\n",
    "\n",
    "for row in ask_posts:\n",
    "    created_at = row[6]\n",
    "    num_comments = int(row[4])\n",
    "    result_list.append((created_at, num_comments))\n",
    "    \n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "\n",
    "for row in result_list:\n",
    "    date = row[0]\n",
    "    date_dt = dt.datetime.strptime(date, \"%m/%d/%Y %H:%M\")\n",
    "    date = date_dt\n",
    "    hour = date.hour\n",
    "    if hour not in counts_by_hour:\n",
    "        counts_by_hour[hour] = 1\n",
    "        comments_by_hour[hour] = row[1] \n",
    "    else:\n",
    "        counts_by_hour[hour] += 1\n",
    "        comments_by_hour[hour] += row[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9, 5.5777777777777775], [13, 14.741176470588234], [10, 13.440677966101696], [14, 13.233644859813085], [16, 16.796296296296298], [23, 7.985294117647059], [12, 9.41095890410959], [17, 11.46], [15, 38.5948275862069], [21, 16.009174311926607], [20, 21.525], [2, 23.810344827586206], [18, 13.20183486238532], [3, 7.796296296296297], [5, 10.08695652173913], [19, 10.8], [1, 11.383333333333333], [22, 6.746478873239437], [8, 10.25], [4, 7.170212765957447], [0, 8.127272727272727], [6, 9.022727272727273], [7, 7.852941176470588], [11, 11.051724137931034]]\n"
     ]
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "for hour in comments_by_hour:\n",
    "    avg_by_hour.append([hour, (comments_by_hour[hour] / counts_by_hour[hour])])\n",
    "print(avg_by_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(5.5777777777777775, 9), (14.741176470588234, 13), (13.440677966101696, 10), (13.233644859813085, 14), (16.796296296296298, 16), (7.985294117647059, 23), (9.41095890410959, 12), (11.46, 17), (38.5948275862069, 15), (16.009174311926607, 21), (21.525, 20), (23.810344827586206, 2), (13.20183486238532, 18), (7.796296296296297, 3), (10.08695652173913, 5), (10.8, 19), (11.383333333333333, 1), (6.746478873239437, 22), (10.25, 8), (7.170212765957447, 4), (8.127272727272727, 0), (9.022727272727273, 6), (7.852941176470588, 7), (11.051724137931034, 11)]\n"
     ]
    }
   ],
   "source": [
    "swap_avg_by_hr = []\n",
    "for row in avg_by_hour:\n",
    "    swap_avg_by_hr.append((row[1], row[0]))\n",
    "\n",
    "print(swap_avg_by_hr)\n",
    "\n",
    "sorted_swap = sorted(swap_avg_by_hr, reverse = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours of Ask Posts Comments\n",
      "[(38.5948275862069, 15), (23.810344827586206, 2), (21.525, 20), (16.796296296296298, 16), (16.009174311926607, 21), (14.741176470588234, 13)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 5 Hours of Ask Posts Comments\")\n",
    "print(sorted_swap[0:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP FIVE:\n",
    "- Now that we have our list sorted in order of average comments per hour, it's time to format our hours into a desired format and round our average comments per hour to 2 decimal places for each row in our sorted list.\n",
    "- First we loop through each row in our sorted list and create a `datetime` object for each hour in our list and then extract the hours and minutes.\n",
    "-Then, we round our average comments per hour to 2 decimal places.\n",
    "-Lastly, we combine our hours and minutes with our rounded average comments per hour in the following string format: `15:00: 38.59 average comments per post`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:00: 38.59 average comments per post\n",
      "2:00: 23.81 average comments per post\n",
      "20:00: 21.52 average comments per post\n",
      "16:00: 16.80 average comments per post\n",
      "21:00: 16.01 average comments per post\n",
      "13:00: 14.74 average comments per post\n",
      "10:00: 13.44 average comments per post\n",
      "14:00: 13.23 average comments per post\n",
      "18:00: 13.20 average comments per post\n",
      "17:00: 11.46 average comments per post\n",
      "1:00: 11.38 average comments per post\n",
      "11:00: 11.05 average comments per post\n",
      "19:00: 10.80 average comments per post\n",
      "8:00: 10.25 average comments per post\n",
      "5:00: 10.09 average comments per post\n",
      "12:00: 9.41 average comments per post\n",
      "6:00: 9.02 average comments per post\n",
      "0:00: 8.13 average comments per post\n",
      "23:00: 7.99 average comments per post\n",
      "7:00: 7.85 average comments per post\n",
      "3:00: 7.80 average comments per post\n",
      "4:00: 7.17 average comments per post\n",
      "22:00: 6.75 average comments per post\n",
      "9:00: 5.58 average comments per post\n"
     ]
    }
   ],
   "source": [
    "for row in sorted_swap:\n",
    "    hour = row[1]\n",
    "    avg_comments_by_hr = row[0] \n",
    "    dt_hr = dt.datetime.strptime(str(hour), \"%H\")\n",
    "    dt_hr = dt_hr.time()\n",
    "    hour = dt_hr.hour\n",
    "    minute = dt_hr.minute\n",
    "    hrs_minutes_only = str(hour) + \":\"+str(minute)+\"0\"\n",
    "    rounded_avg = \": {:.2f} average comments per post\".format(avg_comments_by_hr)\n",
    "    print(hrs_minutes_only + rounded_avg)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FINAL ANALYSIS\n",
    "- As you can see, the 5 hours that contain the most comments on average are: 3pm, 2am, 8pm, 4pm, and 9pm.\n",
    "- 3pm: 38.59 avg comments per post, 2am: 23.81 avg comments per post, 8pm: 21.52 avg comments per post, 4pm: 16.01 avg comments per post, and at 9pm: 16.01 average comments per post.\n",
    "- Between the hours of 1pm and 4pm are usually the most common study/class hours for tech students, and between the hours of 8pm and 2pm students are homework hours typically because typically that's when students are working on homework.\n",
    "-At 2pm, Tech students are commonly forced to do their homework assignments at those late hours because of late shifts, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
